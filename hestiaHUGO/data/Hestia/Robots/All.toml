# Robot Crawler Data File.
#
# NOTE:
#   1. The User-agent's value is defined in the filename. Here is an example for
#      defining the value for this particular user-agent:
#
#               Sitemap = [
#               	"{{ .BaseURL }}/sitemap.xml",
#               ]
#
#               Allow = [
#               	"/",
#               	"/en/",
#               	"/zh-hans",
#               ]
#
#               Disallow = [
#               	"/en/some-path/there/",
#               	"/zh-hans/some-path/here/*",
#               ]
#
#               Crawl-delay = 5
#
#   2. If you need to canonicalize your relative URL with the baseURL, you
#      can use the placeholder "{{ .BaseURL }}". If we follow the example above
#      and the `.BaseURL` is "https://www.example.com", the processing shall
#      be as following output:
#       "{{ .BaseURL }}/sitemap.xml" --> "https://www.example.com/sitemap.xml"
#   3. The field names are case-insensitive (e.g. "Sitemap" and "sitemap" both
#      referring to the same dataset.
#   4. The values are processed with whitespace cleaning.
#   5. Position of the fields are not important due to the key-value nature of
#      the data file.
#   6. Only 1 "All.toml" file is allowed. If there are more than one, the result
#      shall be unpredictable. Please overwrite whenever necessary in your own
#      data/Hestia/Robots/All.toml file.
#   7. All Sitemaps are processed into a unique list of URLs to prevent
#      duplications.
#   8. **You're fully responsible for providing an absolute sitemap URL**
#      based on the user agent data source. The "All.toml" governs the overall
#      Sitemap configurations.
Sitemap = [
	"{{ .BaseURL }}/sitemap.xml",
]




Allow = [
	"/",
]




Disallow = [
]




Crawl-delay = 0
