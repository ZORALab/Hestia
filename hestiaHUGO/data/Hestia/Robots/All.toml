# HESTIA ROBOTS CRAWLER CONFIGURATIONS
# ====================================
# NOTE:
#   1. The User-agent's value is defined in the filename. Here is an example for
#      defining the value for this particular user-agent:
#
#               Sitemap = [
#                       "/sitemap.xml",
#               ]
#
#               Allow = [
#                       "/",
#                       "/en/",
#                       "/zh-hans",
#               ]
#
#               Disallow = [
#                       "/en/some-path/there/",
#                       "/zh-hans/some-path/here/*",
#               ]
#
#               Crawl-delay = 5
#
#   2. For Sitemaps, If you need to canonicalize your relative URL into absolute
#      URL (highly recommended), you can denotes them with the root relative
#      URL (starts with '/'). Hestia will convert it with the given Base URL. If
#      we follow the above example, given a base URL is
#      "https://www.example.com", the processing shall be as follows:
#              "/sitemap.xml" -> "https://www.example.com/sitemap.xml"
#   3. The field names are case-insensitive (e.g. "Sitemap" and "sitemap" both
#      referring to the same dataset.
#   4. The values are processed with whitespace cleaning.
#   5. Position of the fields are not important due to the key-value nature of
#      the data file.
#   6. Only 1 "All.toml" file is allowed. If there are more than one, the result
#      shall be unpredictable. Please overwrite whenever necessary in your own
#      data/Hestia/Robots/All.toml data file.
#   7. All Sitemaps are processed into a unique list of URLs for preventing
#      duplication.
#   8. **You're fully responsible for providing an absolute sitemap URL**
#      based on the user agent data source. The "All.toml" governs the overall
#      Sitemap configurations.
Sitemap = [
	"/sitemap.xml",
]




Allow = [
	"/",
]




Disallow = [
]




Crawl-delay = 0
